{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cdd3b0d",
   "metadata": {},
   "source": [
    "# Tarea 7: Reconocimiento Facial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08dd9fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.1.2\n",
      "CUDA disponible: True\n",
      "GPUs detectadas: 2\n",
      "GPU 0: Tesla P100-PCIE-16GB\n",
      "GPU 1: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import optuna\n",
    "\n",
    "plt.style.use('default')\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA disponible: {torch.cuda.is_available()}\")\n",
    "print(f\"GPUs detectadas: {torch.cuda.device_count()}\")\n",
    "\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "dispositivo = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "usar_multi_gpu = torch.cuda.device_count() > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51fdc243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuracion lista\n"
     ]
    }
   ],
   "source": [
    "class Configuracion:\n",
    "    DIR_BASE = Path(\"/home2/DSMaster/mgarcia/Tarea 7\")\n",
    "    DIR_DATOS = DIR_BASE / \"datos\"\n",
    "    DIR_CELEBA = DIR_DATOS / \"celeba\"\n",
    "    IMAGENES_CELEBA = DIR_CELEBA / \"img_align_celeba\"\n",
    "    ARCHIVO_ATRIBUTOS_CELEBA = DIR_CELEBA / \"list_attr_celeba.txt\"\n",
    "    DIR_MI_ROSTRO = DIR_DATOS / \"mi_rostro\"\n",
    "    DIR_MODELOS = DIR_BASE / \"modelos\"\n",
    "    DIR_RESULTADOS = DIR_BASE / \"resultados\"\n",
    "    DIR_MLRUNS = DIR_BASE / \"mlruns\"\n",
    "    \n",
    "    DIR_MODELOS.mkdir(exist_ok=True)\n",
    "    DIR_RESULTADOS.mkdir(exist_ok=True)\n",
    "    DIR_MLRUNS.mkdir(exist_ok=True)\n",
    "    \n",
    "    TAMANO_IMG = 128\n",
    "    NUM_WORKERS = 8\n",
    "    \n",
    "    LISTA_ATRIBUTOS_CELEBA = [\n",
    "        'Attractive', 'Male', 'Smiling', 'Wearing_Lipstick',\n",
    "        'Young', 'Eyeglasses', 'Black_Hair', 'Blond_Hair', 'Brown_Hair']\n",
    "    \n",
    "    NUM_ATRIBUTOS_CELEBA = len(LISTA_ATRIBUTOS_CELEBA)\n",
    "    \n",
    "    TRIALS_PREENTRENAMIENTO = 5\n",
    "    TRIALS_TRANSFER = 10\n",
    "    TRIALS_FINETUNE = 5\n",
    "    \n",
    "    MLFLOW_URI = f\"file:{DIR_MLRUNS}\"\n",
    "    NOMBRE_EXPERIMENTO = \"reconocimiento_facial_optuna\"\n",
    "    SEMILLA = 42\n",
    "\n",
    "torch.manual_seed(Configuracion.SEMILLA)\n",
    "np.random.seed(Configuracion.SEMILLA)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(Configuracion.SEMILLA)\n",
    "\n",
    "mlflow.set_tracking_uri(Configuracion.MLFLOW_URI)\n",
    "mlflow.set_experiment(Configuracion.NOMBRE_EXPERIMENTO)\n",
    "\n",
    "print(\"Configuracion lista\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cfd2cd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets listos\n"
     ]
    }
   ],
   "source": [
    "class DatasetCelebA(Dataset):\n",
    "    def __init__(self, dir_imagenes, archivo_atributos, atributos, transformacion=None, limite=None):\n",
    "        self.dir_imagenes = Path(dir_imagenes)\n",
    "        self.transformacion = transformacion\n",
    "        self.atributos = atributos\n",
    "        df = pd.read_csv(archivo_atributos)\n",
    "        self.datos = df[['image_id'] + atributos].copy()\n",
    "        for attr in atributos:\n",
    "            self.datos[attr] = (self.datos[attr] + 1) // 2\n",
    "        if limite:\n",
    "            self.datos = self.datos.head(limite)\n",
    "        print(f\"Dataset CelebA: {len(self.datos)} imagenes\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.datos)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        fila = self.datos.iloc[idx]\n",
    "        ruta_img = self.dir_imagenes / fila['image_id']\n",
    "        img = Image.open(ruta_img)\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "        if self.transformacion:\n",
    "            img = np.array(img, dtype=np.uint8)\n",
    "            img = Image.fromarray(img)\n",
    "            img = self.transformacion(img)\n",
    "        etiquetas = torch.tensor(fila[self.atributos].values.astype(np.float32))\n",
    "        return img, etiquetas\n",
    "\n",
    "\n",
    "class DatasetReconocimientoFacial(Dataset):\n",
    "    def __init__(self, dir_positivas, dir_negativas, transformacion=None, muestras_negativas=None):\n",
    "        self.transformacion = transformacion\n",
    "        self.muestras = []\n",
    "        dir_positivas = Path(dir_positivas)\n",
    "        for ext in ['*.jpg', '*.png']:\n",
    "            for ruta_img in dir_positivas.glob(ext):\n",
    "                self.muestras.append((str(ruta_img), 1))\n",
    "        num_positivas = len(self.muestras)\n",
    "        print(f\"Imagenes positivas: {num_positivas}\")\n",
    "        dir_negativas = Path(dir_negativas)\n",
    "        imagenes_negativas = list(dir_negativas.glob('*.jpg'))\n",
    "        if muestras_negativas:\n",
    "            imagenes_negativas = imagenes_negativas[:muestras_negativas]\n",
    "        else:\n",
    "            imagenes_negativas = imagenes_negativas[:num_positivas * 2]\n",
    "        for ruta_img in imagenes_negativas:\n",
    "            self.muestras.append((str(ruta_img), 0))\n",
    "        print(f\"Imagenes negativas: {len(imagenes_negativas)}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.muestras)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        ruta_img, etiqueta = self.muestras[idx]\n",
    "        img = Image.open(ruta_img).convert('RGB')\n",
    "        if self.transformacion:\n",
    "            img = self.transformacion(img)\n",
    "        return img, torch.tensor(etiqueta, dtype=torch.float32)\n",
    "\n",
    "\n",
    "def obtener_transformaciones(tamano_img, aumentar=True):\n",
    "    if aumentar:\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((tamano_img, tamano_img)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(20),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "    \n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((tamano_img, tamano_img)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "print(\"Datasets listos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "656ec5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelos listos\n"
     ]
    }
   ],
   "source": [
    "class ModeloCelebA(nn.Module):\n",
    "    def __init__(self, num_atributos=9, fc_oculto=1024, dropout=0.5):\n",
    "        super().__init__()\n",
    "        canales_conv = [64, 128, 256, 512, 512]\n",
    "        capas = []\n",
    "        canales_entrada = 3\n",
    "        for canales_salida in canales_conv:\n",
    "            capas.extend([\n",
    "                nn.Conv2d(canales_entrada, canales_salida, 3, padding=1),\n",
    "                nn.BatchNorm2d(canales_salida),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(2, 2)\n",
    "            ])\n",
    "            canales_entrada = canales_salida\n",
    "        self.caracteristicas = nn.Sequential(*capas)\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.clasificador = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, fc_oculto),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(fc_oculto, num_atributos))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.clasificador(self.gap(self.caracteristicas(x)))\n",
    "\n",
    "\n",
    "class ModeloReconocimientoFacial(nn.Module):\n",
    "    def __init__(self, modelo_preentrenado, fc_oculto=256, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.caracteristicas = modelo_preentrenado.caracteristicas\n",
    "        self.gap = modelo_preentrenado.gap\n",
    "        self.clasificador = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, fc_oculto),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(fc_oculto, 1))\n",
    "    \n",
    "        for param in self.caracteristicas.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.gap.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.clasificador(self.gap(self.caracteristicas(x))).squeeze(1)\n",
    "    \n",
    "    def descongelar_capas(self, num_capas=6):\n",
    "        for capa in list(self.caracteristicas.children())[-num_capas:]:\n",
    "            for param in capa.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "print(\"Modelos listos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e297f083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funciones de entrenamiento listas\n"
     ]
    }
   ],
   "source": [
    "def entrenar_epoca(modelo, cargador, criterio, optimizador, dispositivo, multietiqueta=False):\n",
    "    modelo.train()\n",
    "    perdida_total = 0.0\n",
    "    correctos = 0\n",
    "    total = 0\n",
    "    for entradas, etiquetas in cargador:\n",
    "        entradas, etiquetas = entradas.to(dispositivo), etiquetas.to(dispositivo)\n",
    "        optimizador.zero_grad()\n",
    "        salidas = modelo(entradas)\n",
    "        perdida = criterio(salidas, etiquetas)\n",
    "        perdida.backward()\n",
    "        optimizador.step()\n",
    "        perdida_total += perdida.item() * entradas.size(0)\n",
    "        predicciones = (torch.sigmoid(salidas) > 0.5).float()\n",
    "        if multietiqueta:\n",
    "            correctos += (predicciones == etiquetas).sum().item()\n",
    "            total += etiquetas.numel()\n",
    "        else:\n",
    "            correctos += (predicciones == etiquetas).sum().item()\n",
    "            total += etiquetas.size(0)\n",
    "    return perdida_total / len(cargador.dataset), correctos / total\n",
    "\n",
    "\n",
    "def validar_epoca(modelo, cargador, criterio, dispositivo, multietiqueta=False):\n",
    "    modelo.eval()\n",
    "    perdida_total = 0.0\n",
    "    correctos = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for entradas, etiquetas in cargador:\n",
    "            entradas, etiquetas = entradas.to(dispositivo), etiquetas.to(dispositivo)\n",
    "            salidas = modelo(entradas)\n",
    "            perdida = criterio(salidas, etiquetas)\n",
    "            perdida_total += perdida.item() * entradas.size(0)\n",
    "            predicciones = (torch.sigmoid(salidas) > 0.5).float()\n",
    "            if multietiqueta:\n",
    "                correctos += (predicciones == etiquetas).sum().item()\n",
    "                total += etiquetas.numel()\n",
    "            else:\n",
    "                correctos += (predicciones == etiquetas).sum().item()\n",
    "                total += etiquetas.size(0)\n",
    "    return perdida_total / len(cargador.dataset), correctos / total\n",
    "\n",
    "print(\"Funciones de entrenamiento listas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1c8d34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando dataset CelebA\n",
      "Dataset CelebA: 202599 imagenes\n",
      "Entrenamiento: 182339\n",
      "Validacion: 20260\n"
     ]
    }
   ],
   "source": [
    "print(\"Cargando dataset CelebA\")\n",
    "\n",
    "dataset_completo = DatasetCelebA(\n",
    "    Configuracion.IMAGENES_CELEBA,\n",
    "    Configuracion.ARCHIVO_ATRIBUTOS_CELEBA,\n",
    "    Configuracion.LISTA_ATRIBUTOS_CELEBA,\n",
    "    transformacion=None,\n",
    "    limite=None)\n",
    "\n",
    "tamano_entrenamiento = int(0.9 * len(dataset_completo))\n",
    "tamano_validacion = len(dataset_completo) - tamano_entrenamiento\n",
    "indices_entrenamiento, indices_validacion = torch.utils.data.random_split(\n",
    "    range(len(dataset_completo)), [tamano_entrenamiento, tamano_validacion])\n",
    "\n",
    "class SubconjuntoTransformado(Dataset):\n",
    "    def __init__(self, dataset, indices, transformacion):\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices\n",
    "        self.transformacion = transformacion\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx_real = self.indices[idx]\n",
    "        fila = self.dataset.datos.iloc[idx_real]\n",
    "        ruta_img = self.dataset.dir_imagenes / fila['image_id']\n",
    "        img = Image.open(ruta_img)\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "        if self.transformacion:\n",
    "            img = np.array(img, dtype=np.uint8)\n",
    "            img = Image.fromarray(img)\n",
    "            img = self.transformacion(img)\n",
    "        etiquetas = torch.tensor(fila[self.dataset.atributos].values.astype(np.float32))\n",
    "        return img, etiquetas\n",
    "\n",
    "print(f\"Entrenamiento: {len(indices_entrenamiento)}\")\n",
    "print(f\"Validacion: {len(indices_validacion)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a4bf881b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-02 01:58:29,625] A new study created in memory with name: preentrenamiento_celeba\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizando hiperparametros de pre-entrenamiento\n",
      "Trials: 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88857f8da8fd4192b166fb51264166a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1194169/1499883838.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  tasa_aprendizaje = trial.suggest_loguniform('tasa_aprendizaje', 1e-4, 1e-2)\n",
      "/tmp/ipykernel_1194169/1499883838.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  decaimiento_peso = trial.suggest_loguniform('decaimiento_peso', 1e-6, 1e-3)\n",
      "/tmp/ipykernel_1194169/1499883838.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout = trial.suggest_uniform('dropout', 0.3, 0.7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-02 02:23:51,024] Trial 0 finished with value: 0.9140890643852144 and parameters: {'tasa_aprendizaje': 0.001211655178066541, 'decaimiento_peso': 3.8792665915804016e-05, 'dropout': 0.4695498190853449, 'fc_oculto': 512, 'tamano_lote': 64}. Best is trial 0 with value: 0.9140890643852144.\n",
      "[I 2025-12-02 03:01:42,909] Trial 1 finished with value: 0.9203082154217396 and parameters: {'tasa_aprendizaje': 0.00033720802263697533, 'decaimiento_peso': 1.023229747601771e-06, 'dropout': 0.49197381781766425, 'fc_oculto': 2048, 'tamano_lote': 32}. Best is trial 1 with value: 0.9203082154217396.\n",
      "[I 2025-12-02 03:38:47,051] Trial 2 finished with value: 0.9202040144784469 and parameters: {'tasa_aprendizaje': 0.00017646555049643132, 'decaimiento_peso': 1.7359348676460013e-05, 'dropout': 0.5570777164689342, 'fc_oculto': 2048, 'tamano_lote': 32}. Best is trial 1 with value: 0.9203082154217396.\n",
      "[I 2025-12-02 04:14:34,333] Trial 3 finished with value: 0.9149994515739827 and parameters: {'tasa_aprendizaje': 0.0021032940102509567, 'decaimiento_peso': 7.423590766255278e-06, 'dropout': 0.6652861777022611, 'fc_oculto': 2048, 'tamano_lote': 32}. Best is trial 1 with value: 0.9203082154217396.\n",
      "[I 2025-12-02 04:39:00,972] Trial 4 finished with value: 0.9132225512778326 and parameters: {'tasa_aprendizaje': 0.0012160395387569706, 'decaimiento_peso': 2.2284434957009167e-05, 'dropout': 0.4343753173480005, 'fc_oculto': 1024, 'tamano_lote': 64}. Best is trial 1 with value: 0.9203082154217396.\n",
      "Mejor accuracy: 0.9203\n",
      "Mejores parametros: {'tasa_aprendizaje': 0.00033720802263697533, 'decaimiento_peso': 1.023229747601771e-06, 'dropout': 0.49197381781766425, 'fc_oculto': 2048, 'tamano_lote': 32}\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimizando hiperparametros de pre-entrenamiento\")\n",
    "print(f\"Trials: {Configuracion.TRIALS_PREENTRENAMIENTO}\")\n",
    "\n",
    "def objetivo_preentrenamiento(trial):\n",
    "    tasa_aprendizaje = trial.suggest_loguniform('tasa_aprendizaje', 1e-4, 1e-2)\n",
    "    decaimiento_peso = trial.suggest_loguniform('decaimiento_peso', 1e-6, 1e-3)\n",
    "    dropout = trial.suggest_uniform('dropout', 0.3, 0.7)\n",
    "    fc_oculto = trial.suggest_categorical('fc_oculto', [512, 1024, 2048])\n",
    "    tamano_lote = trial.suggest_categorical('tamano_lote', [32, 64, 128])\n",
    "    \n",
    "    transformacion_entrenamiento = obtener_transformaciones(Configuracion.TAMANO_IMG, aumentar=True)\n",
    "    transformacion_validacion = obtener_transformaciones(Configuracion.TAMANO_IMG, aumentar=False)\n",
    "    \n",
    "    dataset_entrenamiento = SubconjuntoTransformado(dataset_completo, indices_entrenamiento.indices, transformacion_entrenamiento)\n",
    "    dataset_validacion = SubconjuntoTransformado(dataset_completo, indices_validacion.indices, transformacion_validacion)\n",
    "    \n",
    "    cargador_entrenamiento = DataLoader(dataset_entrenamiento, batch_size=tamano_lote, shuffle=True, \n",
    "                            num_workers=Configuracion.NUM_WORKERS, pin_memory=True)\n",
    "    cargador_validacion = DataLoader(dataset_validacion, batch_size=tamano_lote, shuffle=False,\n",
    "                          num_workers=Configuracion.NUM_WORKERS, pin_memory=True)\n",
    "    \n",
    "    modelo = ModeloCelebA(num_atributos=Configuracion.NUM_ATRIBUTOS_CELEBA, \n",
    "                       fc_oculto=fc_oculto, dropout=dropout)\n",
    "    if usar_multi_gpu:\n",
    "        modelo = nn.DataParallel(modelo)\n",
    "    modelo = modelo.to(dispositivo)\n",
    "    \n",
    "    criterio = nn.BCEWithLogitsLoss()\n",
    "    optimizador = optim.Adam(modelo.parameters(), lr=tasa_aprendizaje, weight_decay=decaimiento_peso)\n",
    "    \n",
    "    mejor_accuracy_val = 0.0\n",
    "    for epoca in range(10):\n",
    "        perdida_entrenamiento, accuracy_entrenamiento = entrenar_epoca(modelo, cargador_entrenamiento, criterio, optimizador, dispositivo, True)\n",
    "        perdida_validacion, accuracy_validacion = validar_epoca(modelo, cargador_validacion, criterio, dispositivo, True)\n",
    "        if accuracy_validacion > mejor_accuracy_val:\n",
    "            mejor_accuracy_val = accuracy_validacion\n",
    "        trial.report(accuracy_validacion, epoca)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "    return mejor_accuracy_val\n",
    "\n",
    "estudio_preentrenamiento = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    study_name='preentrenamiento_celeba',\n",
    "    pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=3))\n",
    "\n",
    "estudio_preentrenamiento.optimize(objetivo_preentrenamiento, n_trials=Configuracion.TRIALS_PREENTRENAMIENTO, show_progress_bar=True)\n",
    "\n",
    "print(f\"Mejor accuracy: {estudio_preentrenamiento.best_value:.4f}\")\n",
    "print(f\"Mejores parametros: {estudio_preentrenamiento.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33e6af5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo pre-entrenado final\n",
      "Epoca 1/20\n",
      "Entrenamiento: 0.2722/0.8786, Validacion: 0.2244/0.9016\n",
      "Epoca 2/20\n",
      "Entrenamiento: 0.2185/0.9049, Validacion: 0.2200/0.9058\n",
      "Epoca 3/20\n",
      "Entrenamiento: 0.2072/0.9097, Validacion: 0.1949/0.9147\n",
      "Epoca 4/20\n",
      "Entrenamiento: 0.2005/0.9127, Validacion: 0.1903/0.9158\n",
      "Epoca 5/20\n",
      "Entrenamiento: 0.1960/0.9146, Validacion: 0.1855/0.9190\n",
      "Epoca 6/20\n",
      "Entrenamiento: 0.1922/0.9162, Validacion: 0.1811/0.9209\n",
      "Epoca 7/20\n",
      "Entrenamiento: 0.1891/0.9174, Validacion: 0.1860/0.9204\n",
      "Epoca 8/20\n",
      "Entrenamiento: 0.1868/0.9189, Validacion: 0.1785/0.9218\n",
      "Epoca 9/20\n",
      "Entrenamiento: 0.1845/0.9197, Validacion: 0.1860/0.9186\n",
      "Epoca 10/20\n",
      "Entrenamiento: 0.1826/0.9206, Validacion: 0.1812/0.9207\n",
      "Epoca 11/20\n",
      "Entrenamiento: 0.1805/0.9214, Validacion: 0.1966/0.9171\n",
      "Epoca 12/20\n",
      "Entrenamiento: 0.1790/0.9219, Validacion: 0.1884/0.9178\n",
      "Epoca 13/20\n",
      "Entrenamiento: 0.1773/0.9227, Validacion: 0.1782/0.9217\n",
      "Epoca 14/20\n",
      "Entrenamiento: 0.1756/0.9234, Validacion: 0.1808/0.9204\n",
      "Epoca 15/20\n",
      "Entrenamiento: 0.1740/0.9239, Validacion: 0.1773/0.9223\n",
      "Epoca 16/20\n",
      "Entrenamiento: 0.1727/0.9245, Validacion: 0.1750/0.9235\n",
      "Epoca 17/20\n",
      "Entrenamiento: 0.1713/0.9251, Validacion: 0.1783/0.9222\n",
      "Epoca 18/20\n",
      "Entrenamiento: 0.1700/0.9255, Validacion: 0.1795/0.9229\n",
      "Epoca 19/20\n",
      "Entrenamiento: 0.1685/0.9262, Validacion: 0.1770/0.9239\n",
      "Epoca 20/20\n",
      "Entrenamiento: 0.1672/0.9269, Validacion: 0.1759/0.9238\n",
      "Pre-entrenamiento completado. Mejor Accuracy Val: 0.9239\n"
     ]
    }
   ],
   "source": [
    "print(\"Entrenando modelo pre-entrenado final\")\n",
    "\n",
    "mejores_params = estudio_preentrenamiento.best_params\n",
    "transformacion_entrenamiento = obtener_transformaciones(Configuracion.TAMANO_IMG, aumentar=True)\n",
    "transformacion_validacion = obtener_transformaciones(Configuracion.TAMANO_IMG, aumentar=False)\n",
    "\n",
    "dataset_entrenamiento = SubconjuntoTransformado(dataset_completo, indices_entrenamiento.indices, transformacion_entrenamiento)\n",
    "dataset_validacion = SubconjuntoTransformado(dataset_completo, indices_validacion.indices, transformacion_validacion)\n",
    "\n",
    "cargador_entrenamiento = DataLoader(dataset_entrenamiento, batch_size=mejores_params['tamano_lote'], \n",
    "                        shuffle=True, num_workers=Configuracion.NUM_WORKERS, pin_memory=True)\n",
    "cargador_validacion = DataLoader(dataset_validacion, batch_size=mejores_params['tamano_lote'],\n",
    "                      shuffle=False, num_workers=Configuracion.NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "modelo_celeba = ModeloCelebA(\n",
    "    num_atributos=Configuracion.NUM_ATRIBUTOS_CELEBA,\n",
    "    fc_oculto=mejores_params['fc_oculto'],\n",
    "    dropout=mejores_params['dropout'])\n",
    "\n",
    "if usar_multi_gpu:\n",
    "    modelo_celeba = nn.DataParallel(modelo_celeba)\n",
    "modelo_celeba = modelo_celeba.to(dispositivo)\n",
    "\n",
    "criterio = nn.BCEWithLogitsLoss()\n",
    "optimizador = optim.Adam(modelo_celeba.parameters(), lr=mejores_params['tasa_aprendizaje'], \n",
    "                      weight_decay=mejores_params['decaimiento_peso'])\n",
    "\n",
    "num_epocas = 20\n",
    "mejor_accuracy_val = 0.0\n",
    "historial_preentrenamiento = {'perdida_entrenamiento': [], 'accuracy_entrenamiento': [], \n",
    "                              'perdida_validacion': [], 'accuracy_validacion': []}\n",
    "\n",
    "for epoca in range(num_epocas):\n",
    "    print(f\"Epoca {epoca+1}/{num_epocas}\")\n",
    "    perdida_entrenamiento, accuracy_entrenamiento = entrenar_epoca(modelo_celeba, cargador_entrenamiento, criterio, optimizador, dispositivo, True)\n",
    "    perdida_validacion, accuracy_validacion = validar_epoca(modelo_celeba, cargador_validacion, criterio, dispositivo, True)\n",
    "    \n",
    "    historial_preentrenamiento['perdida_entrenamiento'].append(perdida_entrenamiento)\n",
    "    historial_preentrenamiento['accuracy_entrenamiento'].append(accuracy_entrenamiento)\n",
    "    historial_preentrenamiento['perdida_validacion'].append(perdida_validacion)\n",
    "    historial_preentrenamiento['accuracy_validacion'].append(accuracy_validacion)\n",
    "    \n",
    "    print(f\"Entrenamiento: {perdida_entrenamiento:.4f}/{accuracy_entrenamiento:.4f}, Validacion: {perdida_validacion:.4f}/{accuracy_validacion:.4f}\")\n",
    "    \n",
    "    if accuracy_validacion > mejor_accuracy_val:\n",
    "        mejor_accuracy_val = accuracy_validacion\n",
    "        modelo_guardar = modelo_celeba.module if usar_multi_gpu else modelo_celeba\n",
    "        torch.save(modelo_guardar.state_dict(), Configuracion.DIR_MODELOS / \"celeba_mejor.pth\")\n",
    "\n",
    "modelo_guardar = modelo_celeba.module if usar_multi_gpu else modelo_celeba\n",
    "torch.save(modelo_guardar.state_dict(), Configuracion.DIR_MODELOS / \"celeba_final.pth\")\n",
    "print(f\"Pre-entrenamiento completado. Mejor Accuracy Val: {mejor_accuracy_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d41d25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando dataset de reconocimiento facial\n",
      "Imagenes positivas: 45\n",
      "Imagenes negativas: 200\n",
      "Entrenamiento: 196\n",
      "Validacion: 49\n"
     ]
    }
   ],
   "source": [
    "print(\"Cargando dataset de reconocimiento facial\")\n",
    "\n",
    "dataset_rostros_completo = DatasetReconocimientoFacial(\n",
    "    Configuracion.DIR_MI_ROSTRO,\n",
    "    Configuracion.IMAGENES_CELEBA,\n",
    "    transformacion=None,\n",
    "    muestras_negativas=200)\n",
    "\n",
    "tamano_entrenamiento = int(0.8 * len(dataset_rostros_completo))\n",
    "tamano_validacion = len(dataset_rostros_completo) - tamano_entrenamiento\n",
    "indices_rostros_entrenamiento, indices_rostros_validacion = torch.utils.data.random_split(\n",
    "    range(len(dataset_rostros_completo)), [tamano_entrenamiento, tamano_validacion])\n",
    "\n",
    "class SubconjuntoRostros(Dataset):\n",
    "    def __init__(self, dataset, indices, transformacion):\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices\n",
    "        self.transformacion = transformacion\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx_real = self.indices[idx]\n",
    "        ruta_img, etiqueta = self.dataset.muestras[idx_real]\n",
    "        img = Image.open(ruta_img).convert('RGB')\n",
    "        if self.transformacion:\n",
    "            img = self.transformacion(img)\n",
    "        return img, torch.tensor(etiqueta, dtype=torch.float32)\n",
    "\n",
    "print(f\"Entrenamiento: {len(indices_rostros_entrenamiento)}\")\n",
    "print(f\"Validacion: {len(indices_rostros_validacion)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "689ab90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-02 11:21:49,210] A new study created in memory with name: transfer_learning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizando hiperparametros de transfer learning\n",
      "Trials: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f5a1716afb4e538d2d7afc67f2f870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1194169/2939482511.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  tasa_aprendizaje = trial.suggest_loguniform('tasa_aprendizaje', 1e-5, 1e-2)\n",
      "/tmp/ipykernel_1194169/2939482511.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  decaimiento_peso = trial.suggest_loguniform('decaimiento_peso', 1e-6, 1e-3)\n",
      "/tmp/ipykernel_1194169/2939482511.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-02 11:22:18,928] Trial 0 finished with value: 1.0 and parameters: {'tasa_aprendizaje': 0.0005837162657342226, 'decaimiento_peso': 5.823618483580234e-05, 'dropout': 0.24976251670165306, 'fc_oculto': 512, 'tamano_lote': 16}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-02 11:22:51,226] Trial 1 finished with value: 0.9795918367346939 and parameters: {'tasa_aprendizaje': 0.004157868720252427, 'decaimiento_peso': 2.483335353558449e-06, 'dropout': 0.33055656180346077, 'fc_oculto': 512, 'tamano_lote': 32}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-02 11:23:19,958] Trial 2 finished with value: 1.0 and parameters: {'tasa_aprendizaje': 0.0030568323149573464, 'decaimiento_peso': 0.0005404294806991425, 'dropout': 0.20597626086770432, 'fc_oculto': 512, 'tamano_lote': 16}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-02 11:23:52,364] Trial 3 finished with value: 0.7959183673469388 and parameters: {'tasa_aprendizaje': 0.00023030466766782914, 'decaimiento_peso': 3.145864602136453e-06, 'dropout': 0.3343538278889559, 'fc_oculto': 256, 'tamano_lote': 32}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-02 11:24:21,747] Trial 4 finished with value: 1.0 and parameters: {'tasa_aprendizaje': 0.0017692585144078838, 'decaimiento_peso': 4.086932014618361e-05, 'dropout': 0.4933840344986778, 'fc_oculto': 512, 'tamano_lote': 16}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-02 11:24:55,031] Trial 5 finished with value: 0.7959183673469388 and parameters: {'tasa_aprendizaje': 2.074445029267882e-05, 'decaimiento_peso': 3.0691877776630476e-05, 'dropout': 0.35483035309170496, 'fc_oculto': 128, 'tamano_lote': 32}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-02 11:25:27,662] Trial 6 finished with value: 0.7959183673469388 and parameters: {'tasa_aprendizaje': 1.2889828495576892e-05, 'decaimiento_peso': 1.8382854357228902e-05, 'dropout': 0.42422896657109493, 'fc_oculto': 128, 'tamano_lote': 32}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-02 11:26:00,198] Trial 7 finished with value: 0.7959183673469388 and parameters: {'tasa_aprendizaje': 0.0001759345491766945, 'decaimiento_peso': 0.00041094174509227847, 'dropout': 0.3270331795908398, 'fc_oculto': 128, 'tamano_lote': 32}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-02 11:26:33,554] Trial 8 finished with value: 0.7959183673469388 and parameters: {'tasa_aprendizaje': 6.791858644024997e-05, 'decaimiento_peso': 0.0007656202347419684, 'dropout': 0.29059507175557087, 'fc_oculto': 512, 'tamano_lote': 32}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-12-02 11:27:05,976] Trial 9 finished with value: 0.8163265306122449 and parameters: {'tasa_aprendizaje': 0.0004992169423661717, 'decaimiento_peso': 4.153145664388576e-06, 'dropout': 0.40804674925779716, 'fc_oculto': 128, 'tamano_lote': 32}. Best is trial 0 with value: 1.0.\n",
      "Mejor accuracy: 1.0000\n",
      "Mejores parametros: {'tasa_aprendizaje': 0.0005837162657342226, 'decaimiento_peso': 5.823618483580234e-05, 'dropout': 0.24976251670165306, 'fc_oculto': 512, 'tamano_lote': 16}\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimizando hiperparametros de transfer learning\")\n",
    "print(f\"Trials: {Configuracion.TRIALS_TRANSFER}\")\n",
    "\n",
    "modelo_base = modelo_celeba.module if usar_multi_gpu else modelo_celeba\n",
    "\n",
    "def objetivo_transfer(trial):\n",
    "    tasa_aprendizaje = trial.suggest_loguniform('tasa_aprendizaje', 1e-5, 1e-2)\n",
    "    decaimiento_peso = trial.suggest_loguniform('decaimiento_peso', 1e-6, 1e-3)\n",
    "    dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
    "    fc_oculto = trial.suggest_categorical('fc_oculto', [128, 256, 512])\n",
    "    tamano_lote = trial.suggest_categorical('tamano_lote', [16, 32, 64])\n",
    "    \n",
    "    transformacion_entrenamiento = obtener_transformaciones(Configuracion.TAMANO_IMG, aumentar=True)\n",
    "    transformacion_validacion = obtener_transformaciones(Configuracion.TAMANO_IMG, aumentar=False)\n",
    "    \n",
    "    dataset_entrenamiento = SubconjuntoRostros(dataset_rostros_completo, indices_rostros_entrenamiento.indices, transformacion_entrenamiento)\n",
    "    dataset_validacion = SubconjuntoRostros(dataset_rostros_completo, indices_rostros_validacion.indices, transformacion_validacion)\n",
    "    \n",
    "    cargador_entrenamiento = DataLoader(dataset_entrenamiento, batch_size=tamano_lote, shuffle=True,\n",
    "                            num_workers=Configuracion.NUM_WORKERS, pin_memory=True)\n",
    "    cargador_validacion = DataLoader(dataset_validacion, batch_size=tamano_lote, shuffle=False,\n",
    "                          num_workers=Configuracion.NUM_WORKERS, pin_memory=True)\n",
    "    \n",
    "    modelo = ModeloReconocimientoFacial(modelo_base, fc_oculto=fc_oculto, dropout=dropout)\n",
    "\n",
    "    # Usar solo GPU 0 para optimizaciÃ³n\n",
    "    modelo = modelo.to('cuda:0')\n",
    "    \n",
    "    criterio = nn.BCEWithLogitsLoss()\n",
    "    parametros_entrenables = [p for p in modelo.parameters() if p.requires_grad]\n",
    "    optimizador = optim.Adam(parametros_entrenables, lr=tasa_aprendizaje, weight_decay=decaimiento_peso)\n",
    "    \n",
    "    mejor_accuracy_val = 0.0\n",
    "    for epoca in range(30):\n",
    "        perdida_entrenamiento, accuracy_entrenamiento = entrenar_epoca(modelo, cargador_entrenamiento, criterio, optimizador, 'cuda:0', False)\n",
    "        perdida_validacion, accuracy_validacion = validar_epoca(modelo, cargador_validacion, criterio, 'cuda:0', False)\n",
    "        if accuracy_validacion > mejor_accuracy_val:\n",
    "            mejor_accuracy_val = accuracy_validacion\n",
    "        trial.report(accuracy_validacion, epoca)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "    return mejor_accuracy_val\n",
    "\n",
    "estudio_transfer = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    study_name='transfer_learning',\n",
    "    pruner=optuna.pruners.MedianPruner(n_startup_trials=10, n_warmup_steps=5))\n",
    "\n",
    "estudio_transfer.optimize(objetivo_transfer, n_trials=Configuracion.TRIALS_TRANSFER, show_progress_bar=True)\n",
    "\n",
    "print(f\"Mejor accuracy: {estudio_transfer.best_value:.4f}\")\n",
    "print(f\"Mejores parametros: {estudio_transfer.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "25211e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo de transfer learning final\n",
      "Epoca 1/50\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home2/DSMaster/mgarcia/miniconda3/envs/rna_pytorch/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\", line 85, in _worker\n    output = module(*input, **kwargs)\n  File \"/home2/DSMaster/mgarcia/miniconda3/envs/rna_pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home2/DSMaster/mgarcia/miniconda3/envs/rna_pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/ipykernel_1194169/2043136025.py\", line 46, in forward\n    return self.clasificador(self.gap(self.caracteristicas(x))).squeeze(1)\n  File \"/home2/DSMaster/mgarcia/miniconda3/envs/rna_pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home2/DSMaster/mgarcia/miniconda3/envs/rna_pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home2/DSMaster/mgarcia/miniconda3/envs/rna_pytorch/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 215, in forward\n    input = module(input)\n  File \"/home2/DSMaster/mgarcia/miniconda3/envs/rna_pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home2/DSMaster/mgarcia/miniconda3/envs/rna_pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home2/DSMaster/mgarcia/miniconda3/envs/rna_pytorch/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 460, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n  File \"/home2/DSMaster/mgarcia/miniconda3/envs/rna_pytorch/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 456, in _conv_forward\n    return F.conv2d(input, weight, bias, self.stride,\nRuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoca \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epocas):\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoca \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoca\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epocas\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m     perdida_entrenamiento, accuracy_entrenamiento \u001b[38;5;241m=\u001b[39m \u001b[43mentrenar_epoca\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelo_rostros\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcargador_entrenamiento\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizador\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdispositivo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     perdida_validacion, accuracy_validacion \u001b[38;5;241m=\u001b[39m validar_epoca(modelo_rostros, cargador_validacion, criterio, dispositivo, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     39\u001b[0m     historial_transfer[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperdida_entrenamiento\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(perdida_entrenamiento)\n",
      "Cell \u001b[0;32mIn[33], line 9\u001b[0m, in \u001b[0;36mentrenar_epoca\u001b[0;34m(modelo, cargador, criterio, optimizador, dispositivo, multietiqueta)\u001b[0m\n\u001b[1;32m      7\u001b[0m entradas, etiquetas \u001b[38;5;241m=\u001b[39m entradas\u001b[38;5;241m.\u001b[39mto(dispositivo), etiquetas\u001b[38;5;241m.\u001b[39mto(dispositivo)\n\u001b[1;32m      8\u001b[0m optimizador\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 9\u001b[0m salidas \u001b[38;5;241m=\u001b[39m \u001b[43mmodelo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentradas\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m perdida \u001b[38;5;241m=\u001b[39m criterio(salidas, etiquetas)\n\u001b[1;32m     11\u001b[0m perdida\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/rna_pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rna_pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rna_pytorch/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:185\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodule_kwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    184\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 185\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/rna_pytorch/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:200\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparallel_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, replicas: Sequence[T], inputs: Sequence[Any], kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Any]:\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rna_pytorch/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:110\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m    108\u001b[0m     output \u001b[38;5;241m=\u001b[39m results[i]\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[0;32m--> 110\u001b[0m         output\u001b[38;5;241m.\u001b[39mreraise()\n\u001b[1;32m    111\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/rna_pytorch/lib/python3.10/site-packages/torch/_utils.py:694\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home2/DSMaster/mgarcia/miniconda3/envs/rna_pytorch/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\", line 85, in _worker\n    output = module(*input, **kwargs)\n  File \"/home2/DSMaster/mgarcia/miniconda3/envs/rna_pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home2/DSMaster/mgarcia/miniconda3/envs/rna_pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/ipykernel_1194169/2043136025.py\", line 46, in forward\n    return self.clasificador(self.gap(self.caracteristicas(x))).squeeze(1)\n  File \"/home2/DSMaster/mgarcia/miniconda3/envs/rna_pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home2/DSMaster/mgarcia/miniconda3/envs/rna_pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home2/DSMaster/mgarcia/miniconda3/envs/rna_pytorch/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 215, in forward\n    input = module(input)\n  File \"/home2/DSMaster/mgarcia/miniconda3/envs/rna_pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home2/DSMaster/mgarcia/miniconda3/envs/rna_pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home2/DSMaster/mgarcia/miniconda3/envs/rna_pytorch/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 460, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n  File \"/home2/DSMaster/mgarcia/miniconda3/envs/rna_pytorch/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 456, in _conv_forward\n    return F.conv2d(input, weight, bias, self.stride,\nRuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED\n"
     ]
    }
   ],
   "source": [
    "print(\"Entrenando modelo de transfer learning final\")\n",
    "\n",
    "mejores_params_transfer = estudio_transfer.best_params\n",
    "transformacion_entrenamiento = obtener_transformaciones(Configuracion.TAMANO_IMG, aumentar=True)\n",
    "transformacion_validacion = obtener_transformaciones(Configuracion.TAMANO_IMG, aumentar=False)\n",
    "\n",
    "dataset_entrenamiento = SubconjuntoRostros(dataset_rostros_completo, indices_rostros_entrenamiento.indices, transformacion_entrenamiento)\n",
    "dataset_validacion = SubconjuntoRostros(dataset_rostros_completo, indices_rostros_validacion.indices, transformacion_validacion)\n",
    "\n",
    "cargador_entrenamiento = DataLoader(dataset_entrenamiento, batch_size=mejores_params_transfer['tamano_lote'],\n",
    "                        shuffle=True, num_workers=Configuracion.NUM_WORKERS, pin_memory=True)\n",
    "cargador_validacion = DataLoader(dataset_validacion, batch_size=mejores_params_transfer['tamano_lote'],\n",
    "                      shuffle=False, num_workers=Configuracion.NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "modelo_rostros = ModeloReconocimientoFacial(\n",
    "    modelo_base,\n",
    "    fc_oculto=mejores_params_transfer['fc_oculto'],\n",
    "    dropout=mejores_params_transfer['dropout'])\n",
    "\n",
    "if usar_multi_gpu:\n",
    "    modelo_rostros = nn.DataParallel(modelo_rostros)\n",
    "modelo_rostros = modelo_rostros.to(dispositivo)\n",
    "\n",
    "criterio = nn.BCEWithLogitsLoss()\n",
    "parametros_entrenables = [p for p in modelo_rostros.parameters() if p.requires_grad]\n",
    "optimizador = optim.Adam(parametros_entrenables, lr=mejores_params_transfer['tasa_aprendizaje'],\n",
    "                      weight_decay=mejores_params_transfer['decaimiento_peso'])\n",
    "\n",
    "num_epocas = 50\n",
    "mejor_accuracy_val = 0.0\n",
    "historial_transfer = {'perdida_entrenamiento': [], 'accuracy_entrenamiento': [], \n",
    "                     'perdida_validacion': [], 'accuracy_validacion': []}\n",
    "\n",
    "for epoca in range(num_epocas):\n",
    "    print(f\"Epoca {epoca+1}/{num_epocas}\")\n",
    "    perdida_entrenamiento, accuracy_entrenamiento = entrenar_epoca(modelo_rostros, cargador_entrenamiento, criterio, optimizador, dispositivo, False)\n",
    "    perdida_validacion, accuracy_validacion = validar_epoca(modelo_rostros, cargador_validacion, criterio, dispositivo, False)\n",
    "    \n",
    "    historial_transfer['perdida_entrenamiento'].append(perdida_entrenamiento)\n",
    "    historial_transfer['accuracy_entrenamiento'].append(accuracy_entrenamiento)\n",
    "    historial_transfer['perdida_validacion'].append(perdida_validacion)\n",
    "    historial_transfer['accuracy_validacion'].append(accuracy_validacion)\n",
    "    \n",
    "    print(f\"Entrenamiento: {perdida_entrenamiento:.4f}/{accuracy_entrenamiento:.4f}, Validacion: {perdida_validacion:.4f}/{accuracy_validacion:.4f}\")\n",
    "    \n",
    "    if accuracy_validacion > mejor_accuracy_val:\n",
    "        mejor_accuracy_val = accuracy_validacion\n",
    "        modelo_guardar = modelo_rostros.module if usar_multi_gpu else modelo_rostros\n",
    "        torch.save(modelo_guardar.state_dict(), Configuracion.DIR_MODELOS / \"transfer_mejor.pth\")\n",
    "\n",
    "print(f\"Transfer learning completado. Mejor Accuracy Val: {mejor_accuracy_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4bf35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimizando hiperparametros de fine-tuning\")\n",
    "print(f\"Trials: {Configuracion.TRIALS_FINETUNE}\")\n",
    "\n",
    "def objetivo_finetune(trial):\n",
    "    tasa_aprendizaje = trial.suggest_loguniform('tasa_aprendizaje', 1e-6, 1e-3)\n",
    "    decaimiento_peso = trial.suggest_loguniform('decaimiento_peso', 1e-7, 1e-4)\n",
    "    num_capas_descongelar = trial.suggest_int('num_capas_descongelar', 4, 10)\n",
    "    tamano_lote = trial.suggest_categorical('tamano_lote', [16, 32])\n",
    "    \n",
    "    transformacion_entrenamiento = obtener_transformaciones(Configuracion.TAMANO_IMG, aumentar=True)\n",
    "    transformacion_validacion = obtener_transformaciones(Configuracion.TAMANO_IMG, aumentar=False)\n",
    "    \n",
    "    dataset_entrenamiento = SubconjuntoRostros(dataset_rostros_completo, indices_rostros_entrenamiento.indices, transformacion_entrenamiento)\n",
    "    dataset_validacion = SubconjuntoRostros(dataset_rostros_completo, indices_rostros_validacion.indices, transformacion_validacion)\n",
    "    \n",
    "    cargador_entrenamiento = DataLoader(dataset_entrenamiento, batch_size=tamano_lote, shuffle=True,\n",
    "                            num_workers=Configuracion.NUM_WORKERS, pin_memory=True)\n",
    "    cargador_validacion = DataLoader(dataset_validacion, batch_size=tamano_lote, shuffle=False,\n",
    "                          num_workers=Configuracion.NUM_WORKERS, pin_memory=True)\n",
    "    \n",
    "    modelo = ModeloReconocimientoFacial(\n",
    "        modelo_base,\n",
    "        fc_oculto=mejores_params_transfer['fc_oculto'],\n",
    "        dropout=mejores_params_transfer['dropout'])\n",
    "    \n",
    "    modelo.descongelar_capas(num_capas=num_capas_descongelar)\n",
    "    \n",
    "    if usar_multi_gpu:\n",
    "        modelo = nn.DataParallel(modelo)\n",
    "    modelo = modelo.to(dispositivo)\n",
    "    \n",
    "    criterio = nn.BCEWithLogitsLoss()\n",
    "    optimizador = optim.Adam(modelo.parameters(), lr=tasa_aprendizaje, weight_decay=decaimiento_peso)\n",
    "    \n",
    "    mejor_accuracy_val = 0.0\n",
    "    for epoca in range(20):\n",
    "        perdida_entrenamiento, accuracy_entrenamiento = entrenar_epoca(modelo, cargador_entrenamiento, criterio, optimizador, dispositivo, False)\n",
    "        perdida_validacion, accuracy_validacion = validar_epoca(modelo, cargador_validacion, criterio, dispositivo, False)\n",
    "        if accuracy_validacion > mejor_accuracy_val:\n",
    "            mejor_accuracy_val = accuracy_validacion\n",
    "        trial.report(accuracy_validacion, epoca)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "    return mejor_accuracy_val\n",
    "\n",
    "estudio_finetune = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    study_name='fine_tuning',\n",
    "    pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=3))\n",
    "\n",
    "estudio_finetune.optimize(objetivo_finetune, n_trials=Configuracion.TRIALS_FINETUNE, show_progress_bar=True)\n",
    "\n",
    "print(f\"Mejor accuracy: {estudio_finetune.best_value:.4f}\")\n",
    "print(f\"Mejores parametros: {estudio_finetune.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757403f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Entrenando modelo final con fine-tuning\")\n",
    "\n",
    "mejores_params_finetune = estudio_finetune.best_params\n",
    "transformacion_entrenamiento = obtener_transformaciones(Configuracion.TAMANO_IMG, aumentar=True)\n",
    "transformacion_validacion = obtener_transformaciones(Configuracion.TAMANO_IMG, aumentar=False)\n",
    "\n",
    "dataset_entrenamiento = SubconjuntoRostros(dataset_rostros_completo, indices_rostros_entrenamiento.indices, transformacion_entrenamiento)\n",
    "dataset_validacion = SubconjuntoRostros(dataset_rostros_completo, indices_rostros_validacion.indices, transformacion_validacion)\n",
    "\n",
    "cargador_entrenamiento = DataLoader(dataset_entrenamiento, batch_size=mejores_params_finetune['tamano_lote'],\n",
    "                        shuffle=True, num_workers=Configuracion.NUM_WORKERS, pin_memory=True)\n",
    "cargador_validacion = DataLoader(dataset_validacion, batch_size=mejores_params_finetune['tamano_lote'],\n",
    "                      shuffle=False, num_workers=Configuracion.NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "modelo_final = ModeloReconocimientoFacial(\n",
    "    modelo_base,\n",
    "    fc_oculto=mejores_params_transfer['fc_oculto'],\n",
    "    dropout=mejores_params_transfer['dropout'])\n",
    "\n",
    "modelo_final.descongelar_capas(num_capas=mejores_params_finetune['num_capas_descongelar'])\n",
    "\n",
    "if usar_multi_gpu:\n",
    "    modelo_final = nn.DataParallel(modelo_final)\n",
    "modelo_final = modelo_final.to(dispositivo)\n",
    "\n",
    "criterio = nn.BCEWithLogitsLoss()\n",
    "optimizador = optim.Adam(modelo_final.parameters(), lr=mejores_params_finetune['tasa_aprendizaje'],\n",
    "                      weight_decay=mejores_params_finetune['decaimiento_peso'])\n",
    "\n",
    "num_epocas = 30\n",
    "mejor_accuracy_val = 0.0\n",
    "historial_finetune = {'perdida_entrenamiento': [], 'accuracy_entrenamiento': [], \n",
    "                     'perdida_validacion': [], 'accuracy_validacion': []}\n",
    "\n",
    "for epoca in range(num_epocas):\n",
    "    print(f\"Epoca {epoca+1}/{num_epocas}\")\n",
    "    perdida_entrenamiento, accuracy_entrenamiento = entrenar_epoca(modelo_final, cargador_entrenamiento, criterio, optimizador, dispositivo, False)\n",
    "    perdida_validacion, accuracy_validacion = validar_epoca(modelo_final, cargador_validacion, criterio, dispositivo, False)\n",
    "    \n",
    "    historial_finetune['perdida_entrenamiento'].append(perdida_entrenamiento)\n",
    "    historial_finetune['accuracy_entrenamiento'].append(accuracy_entrenamiento)\n",
    "    historial_finetune['perdida_validacion'].append(perdida_validacion)\n",
    "    historial_finetune['accuracy_validacion'].append(accuracy_validacion)\n",
    "    \n",
    "    print(f\"Entrenamiento: {perdida_entrenamiento:.4f}/{accuracy_entrenamiento:.4f}, Validacion: {perdida_validacion:.4f}/{accuracy_validacion:.4f}\")\n",
    "    \n",
    "    if accuracy_validacion > mejor_accuracy_val:\n",
    "        mejor_accuracy_val = accuracy_validacion\n",
    "        modelo_guardar = modelo_final.module if usar_multi_gpu else modelo_final\n",
    "        torch.save(modelo_guardar.state_dict(), Configuracion.DIR_MODELOS / \"final_mejor.pth\")\n",
    "\n",
    "modelo_guardar = modelo_final.module if usar_multi_gpu else modelo_final\n",
    "torch.save(modelo_guardar.state_dict(), Configuracion.DIR_MODELOS / \"modelo_final.pth\")\n",
    "print(f\"Fine-tuning completado. Mejor Accuracy Val: {mejor_accuracy_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b73537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "print(\"Evaluacion final\")\n",
    "\n",
    "modelo_final.eval()\n",
    "todas_predicciones = []\n",
    "todas_etiquetas = []\n",
    "todas_probabilidades = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for entradas, etiquetas in cargador_validacion:\n",
    "        entradas = entradas.to(dispositivo)\n",
    "        salidas = modelo_final(entradas)\n",
    "        probabilidades = torch.sigmoid(salidas)\n",
    "        predicciones = (probabilidades > 0.5).float()\n",
    "        todas_predicciones.extend(predicciones.cpu().numpy())\n",
    "        todas_etiquetas.extend(etiquetas.numpy())\n",
    "        todas_probabilidades.extend(probabilidades.cpu().numpy())\n",
    "\n",
    "todas_predicciones = np.array(todas_predicciones)\n",
    "todas_etiquetas = np.array(todas_etiquetas)\n",
    "todas_probabilidades = np.array(todas_probabilidades)\n",
    "\n",
    "metricas = {\n",
    "    'accuracy': accuracy_score(todas_etiquetas, todas_predicciones),\n",
    "    'precision': precision_score(todas_etiquetas, todas_predicciones),\n",
    "    'recall': recall_score(todas_etiquetas, todas_predicciones),\n",
    "    'f1_score': f1_score(todas_etiquetas, todas_predicciones),\n",
    "    'auc_roc': roc_auc_score(todas_etiquetas, todas_probabilidades)}\n",
    "\n",
    "matriz_confusion = confusion_matrix(todas_etiquetas, todas_predicciones)\n",
    "\n",
    "print(\"Metricas finales:\")\n",
    "for k, v in metricas.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "print(\"\\nMatriz de confusion:\")\n",
    "print(matriz_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b298ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(15, 12))\n",
    "\n",
    "axes[0,0].plot(historial_preentrenamiento['perdida_entrenamiento'], label='Entrenamiento')\n",
    "axes[0,0].plot(historial_preentrenamiento['perdida_validacion'], label='Validacion')\n",
    "axes[0,0].set_title('Pre-entrenamiento - Perdida')\n",
    "axes[0,0].legend()\n",
    "\n",
    "axes[0,1].plot(historial_preentrenamiento['accuracy_entrenamiento'], label='Entrenamiento')\n",
    "axes[0,1].plot(historial_preentrenamiento['accuracy_validacion'], label='Validacion')\n",
    "axes[0,1].set_title('Pre-entrenamiento - Accuracy')\n",
    "axes[0,1].legend()\n",
    "\n",
    "axes[1,0].plot(historial_transfer['perdida_entrenamiento'], label='Entrenamiento')\n",
    "axes[1,0].plot(historial_transfer['perdida_validacion'], label='Validacion')\n",
    "axes[1,0].set_title('Transfer Learning - Perdida')\n",
    "axes[1,0].legend()\n",
    "\n",
    "axes[1,1].plot(historial_transfer['accuracy_entrenamiento'], label='Entrenamiento')\n",
    "axes[1,1].plot(historial_transfer['accuracy_validacion'], label='Validacion')\n",
    "axes[1,1].set_title('Transfer Learning - Accuracy')\n",
    "axes[1,1].legend()\n",
    "\n",
    "axes[2,0].plot(historial_finetune['perdida_entrenamiento'], label='Entrenamiento')\n",
    "axes[2,0].plot(historial_finetune['perdida_validacion'], label='Validacion')\n",
    "axes[2,0].set_title('Fine-tuning - Perdida')\n",
    "axes[2,0].legend()\n",
    "\n",
    "axes[2,1].plot(historial_finetune['accuracy_entrenamiento'], label='Entrenamiento')\n",
    "axes[2,1].plot(historial_finetune['accuracy_validacion'], label='Validacion')\n",
    "axes[2,1].set_title('Fine-tuning - Accuracy')\n",
    "axes[2,1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(Configuracion.DIR_RESULTADOS / 'curvas_entrenamiento.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(matriz_confusion, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Matriz de Confusion')\n",
    "plt.ylabel('Real')\n",
    "plt.xlabel('Predicho')\n",
    "plt.savefig(Configuracion.DIR_RESULTADOS / 'matriz_confusion.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e32faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumen = f\"\"\"\n",
    "Pre-entrenamiento:\n",
    "  Trials: {Configuracion.TRIALS_PREENTRENAMIENTO}\n",
    "  Mejores parametros: {estudio_preentrenamiento.best_params}\n",
    "  Mejor accuracy validacion: {estudio_preentrenamiento.best_value:.4f}\n",
    "  Accuracy validacion final: {historial_preentrenamiento['accuracy_validacion'][-1]:.4f}\n",
    "\n",
    "Transfer Learning:\n",
    "  Trials: {Configuracion.TRIALS_TRANSFER}\n",
    "  Mejores parametros: {estudio_transfer.best_params}\n",
    "  Mejor accuracy validacion: {estudio_transfer.best_value:.4f}\n",
    "  Accuracy validacion final: {historial_transfer['accuracy_validacion'][-1]:.4f}\n",
    "\n",
    "Fine-tuning:\n",
    "  Trials: {Configuracion.TRIALS_FINETUNE}\n",
    "  Mejores parametros: {estudio_finetune.best_params}\n",
    "  Mejor accuracy validacion: {estudio_finetune.best_value:.4f}\n",
    "  Accuracy validacion final: {historial_finetune['accuracy_validacion'][-1]:.4f}\n",
    "\n",
    "Metricas Finales:\n",
    "  Accuracy: {metricas['accuracy']:.4f}\n",
    "  Precision: {metricas['precision']:.4f}\n",
    "  Recall: {metricas['recall']:.4f}\n",
    "  F1-Score: {metricas['f1_score']:.4f}\n",
    "  AUC-ROC: {metricas['auc_roc']:.4f}\n",
    "\"\"\"\n",
    "\n",
    "print(resumen)\n",
    "\n",
    "with open(Configuracion.DIR_RESULTADOS / 'resumen.txt', 'w') as f:\n",
    "    f.write(resumen)\n",
    "\n",
    "print(\"\\nEntrenamiento completado\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rna_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
